{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c7094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install argparse\n",
    "#!pip3 install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc1e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pytesseract as py\n",
    "import pandas as pd\n",
    "#from utils import logger as logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de707854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nap = argparse.ArgumentParser()\\nap.add_argument('-i', '--image', required=True,\\n                help = 'path to input image')\\nargs = ap.parse_args()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('-i', '--image', required=True,\n",
    "                help = 'path to input image')\n",
    "args = ap.parse_args()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4faa591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using YOLO-V3 \n",
    "\n",
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    " \n",
    "#reading the image file\n",
    "image = cv2.imread('images/repo5.jpg')\n",
    "\n",
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open('yolov3-classes.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'cfg/yolov3-custom.cfg')\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outs = net.forward(get_output_layers(net))\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[:5]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([round(x), round(y), round(w), round(h)])\n",
    "\n",
    "\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a982dd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107, 360, 378, 345, 354, 369, 347, 353, 371, 377, 365, 356, 374,\n",
       "       368, 380, 350, 362, 344,  18, 359,  36, 346,  57,  76,  97, 146,\n",
       "       121, 341,  35,  17, 302, 263, 185, 224, 120,  56, 343, 145,  96,\n",
       "        75, 340, 349, 262, 301,  16,  95, 261, 119,  55, 144, 339, 321,\n",
       "       327, 312, 303,  83, 308,  33,  15, 338, 311, 314,  32, 323, 335,\n",
       "       332, 317,  53, 329, 326, 299,  54,  72, 320,  94,  73,  93, 117,\n",
       "       305, 142, 143, 260, 118,  14, 221, 220, 310, 337, 182, 304, 259,\n",
       "       298, 334,  31,  71, 219, 249, 132, 285, 294, 267, 269, 268, 272,\n",
       "       275,  30, 293, 296,  12, 278, 290, 284, 266,  29, 140,  91, 115,\n",
       "        51,  90,  70, 257, 265, 179, 218,  11, 177, 243, 237,  43, 225,\n",
       "        99, 230, 233, 229, 236, 227,   9, 239,  27, 254,  26, 245,  88,\n",
       "       137, 112,  48,  67, 215, 176,   7,  59, 204, 195, 191, 194, 190,\n",
       "         6, 188, 197, 200,  24,  45,  23, 134, 206,   5,  22, 168, 150,\n",
       "       159, 124,  78,   0, 152, 149,   3, 155,  21, 151, 131,  42, 158,\n",
       "        82, 161, 106,  61,   2,  39, 122], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf9b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 1068, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9685ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------------------------OCR-------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#cropping detected objects and passing into tesseract OCR\n",
    "A = []\n",
    "for i in indices:\n",
    "    box = boxes[i]\n",
    "    #print(str(i), box[0], box[1], box[2], box[3])\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    crop_img = image[y:y+h, x:x+w]\n",
    "    if crop_img.shape[0] > 0 and crop_img.shape[1] > 0:\n",
    "#         print(crop_img.shape)\n",
    "#         cv2.imshow('crop',image)\n",
    "        cv2.imwrite(\"Crop/crop__\" + str(i) + \".jpg\",crop_img)\n",
    "        # grayscale region within bounding box\n",
    "        gray = cv2.cvtColor(crop_img, cv2.COLOR_RGB2GRAY)\n",
    "        # resize image to three times as large as original for better readability\n",
    "        gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "        # perform gaussian blur to smoothen image\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        # threshold the image using Otsus method to preprocess for tesseract\n",
    "        ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "        #perfrom bitwise not to flip image to black text on white background\n",
    "        roi = cv2.bitwise_not(thresh)\n",
    "        #saving the roi regions\n",
    "        cv2.imwrite(\"Crop/roi__\" + str(i) + \".jpg\",roi)\n",
    "        #passing to tesseract\n",
    "        c = py.image_to_string(roi, config = '--oem 3')\n",
    "        A.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d41c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4f963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BY : SELF (7824357519), KALPANA MEDIC!\\nLAB, BIHUTOLI ROAD ,HOJAL ASSAM\\n\"ASKED —s: AAROGYAM C ™\\n\\n',\n",
       " 'LU ote Er to”\\n\\nPHOTOMETRY\\n\\nnical conditions.\\n',\n",
       " '',\n",
       " 'Or ih wh TREO\\n\\nA ALB/GLOBULIN RATIO\\nf GLOBULIN __\\n\\ne correlate with clinical conditions.\\n\\nCA\\n\\nPi\\n',\n",
       " 'CALCULATED\\nPHOTOMETRY\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'i wine thyrocare.com\\n\\nDAT :\\n\\\\NA MEDICOS AND CITY\\n,/HOJAI ,ASSAM 782435,782435\\n',\n",
       " 'ma/di\\nma/dl\\nU/|\\nU/!\\nU/|\\ngm/di\\ngm/dl\\n\\n<O.%\\n0-0.9\\n< 55\\n\\n< 35\\n\\n< 45\\n5.7-8.2\\n3.2-4.8\\n',\n",
       " 'CTED AT :\\nALPANA MEDICOS AND CITY\\nOAD ,HOJAI ,ASSAM 782435,782435\\n\\nLLiaTrTre BImmbae Ai PARIeeE\\n',\n",
       " 'nyrocare’\\n\\nink Thyroid. Think Thyrocare.\\n\\nmaa: - 400703\\n“ TNyrocare.com\\n\\n',\n",
       " 'UE =—sUNITS.—_—s NORMAL RANGE\\nU/L 45 - 129\\nmaq/dl 0.3-1.2\\n',\n",
       " 'UsI\\ngm/di\\ngm/dl\\nRatio\\nqm/dt\\n\\n< 49\\n\\n5.7-8.2\\n3.2-4.8\\n0.9-2\\n2.5-3.4\\n',\n",
       " 'nditions.\\n\\nPHOTOMETRY\\nPHOTOMETRY\\nCALCULATED\\n\\nPHOTOMETRY\\n',\n",
       " 'ae FS ON eee FN Sainte ws?\\n\\nPHOTOMETRY 7.14\\nPHOTOMETRY 3.93\\nRATIO CALCULATED\\nPHOTOMETRY\\n\\nclinical conditions.\\n\\n',\n",
       " 'ALANINE TRANSAMINASE (SGPT)\\n\\nPROTEIN - TOTAL\\n\\nALBUMIN - SERUM\\n\\nSERUM ALB/GLOBULIN RATIO\\n\\nSERUM GLOBULIN _\\n\\nPlease correlate with clinical conditions.\\n',\n",
       " ': ASHIM SENGUPTA (58Y/M) SAMPLE COLLECTED AT :\\n\\n: SELF (7824357519), KALPANA MEDICOS AND CITY\\nLAB, BIHUTOLI ROAD ,HOJAI ,ASSAM 782435,782435\\n: AAROGYAM C\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Thyrocare’\\n\\nThink Thyroid. Think Thyrocare.\\n',\n",
       " '- BB\\n\\n©. “enone, Navi Mumgaa: - 400703\\nCare.com Ci www thyrocare.com\\n\\n-fOLlercrren AT «\\n',\n",
       " '?\\n\\n9\\n\\nU/L\\nma/dl\\nmg/dl\\nma/di\\nU/I\\nu/I\\n\\n45 - 129\\n0.3-1.2\\n<O0.%\\n0-0.9\\n\\n< 55\\n\\n< 35\\n',\n",
       " 'he F\\n\\nRECT)\\n\\nfL TRANSFERASE (GGT)\\nJOTRANSFERASE (SGOT )\\nMINASE (SGPT)\\n\\nwr Se eee\\n\\nCALCULATED\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\n\\nDLIMATARMCTDY\\n\\nweow\\n\\n0.39\\n34.3\\n33.1\\n38.9\\n\\n7.14\\n2» ar\\n\\n',\n",
       " 'TECHNOLOGY\\nIHATASE PHOTOMETRY\\n\\nAl DLIKMATNASCTOV nov\\n',\n",
       " 'PF ier NS a 1 eM UME\\n\\nSFERASE (SGOT )\\n: (SGPT)\\n\\nATIO\\n\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nCALCULATED\\n\\nDUOTOMFETRY\\n\\n33.1\\n38.9\\n7.14\\n3.93\\n1.22\\n371\\n\\nU/!\\n\\nU/I|\\ngm/di\\ngm/dl\\nRatio\\nam/dL\\n',\n",
       " '33.1\\n38.9\\n7.14\\n3.93\\n1.22\\n\\n3 34\\n\\n“rt\\nU/l\\nU/l\\nam/di\\ngm/dl\\nRatio\\nprmefAt\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ASE (GGT)\\nASE (SGOT )\\nPT)\\n\\nMe See eee,\\n\\nCALCULATED\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nDHOTOMETRY\\n',\n",
       " 'BILIRUBIN -DIRECT\\n\\nBILIRUBIN (INDIRECT)\\n\\nGAMMA GLUTAMYL TRANSFERASE (GGT)\\nASPARTATE AMINOTRANSFERASE (SGOT )\\nALANINE TRANSAMINASE (SGPT)\\nPROTEIN - TOTAL\\n\\nALBUMIN - SERUM\\n\\nPHOTOMET\\nCALCULATE\\nPHOTOMET\\nPHOTOMET\\nPHOTOMET\\nPHOTOMET\\nPHOTOMET\\n',\n",
       " 'AllylUValy\\nee qoghunathpur, Think Thyroid. Think Thyrocare..\\n\\n‘ate Office : Thyrocare Technologies Limited 9 D-37/3, TTC MIDC. Turbhe, Navi Mumbai - 400703\\n2 3030 0000 42252525 Wssy 1865066 & wellness@thyrocare.com @ www.thyrocare.com\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Corporate Office : Thyrocare Technologies Limited 9 D-37/3, TTC MIDC. Turbhe, Navi Mumbai - 400703\\n©) 022 3090 0000 422572525 @ssy 1865066 Sa wellness@thyrocare.com €)www.thyrocare.com\\n\\n: ASHIM SENGUPTA (S8Y/M) CAMDIE CRIIECrTEen aT .\\n',\n",
       " '>) PRHULOUNEIRG\\n\\nPHOTOMETRY 0.5;\\nPHOTOMETRY 0.18\\nCALCULATED 0.35\\nINSFERASE (GGT) PHOTOMETRY 34.:\\n\\nNSFERASE (SGOT ) PHOTOMETRY 33.:\\n\\nee Te Pane ee OL oe mt a 2 yO £\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Thyrocai\\n\\nThink Thyroid. Think Thyro\\n\\nlathpur,\\n',\n",
       " 'ASE\\n\\n_TECHNOLOGY\\n\\nPHOTOMETRY\\nPHOTOMETRY\\nPHOTOMETRY\\nCALCULATED\\n\\nVALUE\\n67\\n0.57\\n0.18\\n0.39\\n\\nUNITS\\nU/L\\nmg/dl\\nmg/dl\\nmo/dl\\n',\n",
       " 'EST NAME TECH!\\n\\nLKALINE PHOSPHATASE _— PHOTC\\nILIRUBIN - TOTAL PHOTC\\nILIRUBIN -DIRECT PHOTC\\n\\nILIRUBIN (INDIRECT) CALCU\\n\\nee a a a ee ee ote mer.\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e0e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BY : SELF (7824357519), KALPANA MEDIC!', 'LAB, BIHUTOLI ROAD ,HOJAL ASSAM', '\"ASKED —s: AAROGYAM C ™', '', '']\n",
      "['LU ote Er to”', '', 'PHOTOMETRY', '', 'nical conditions.', '']\n",
      "['']\n",
      "['Or ih wh TREO', '', 'A ALB/GLOBULIN RATIO', 'f GLOBULIN __', '', 'e correlate with clinical conditions.', '', 'CA', '', 'Pi', '']\n",
      "['CALCULATED', 'PHOTOMETRY', '', '']\n",
      "[['BY : SELF (7824357519), KALPANA MEDIC!', 'LAB, BIHUTOLI ROAD ,HOJAL ASSAM', '\"ASKED —s: AAROGYAM C ™', '', ''], ['LU ote Er to”', '', 'PHOTOMETRY', '', 'nical conditions.', ''], [''], ['Or ih wh TREO', '', 'A ALB/GLOBULIN RATIO', 'f GLOBULIN __', '', 'e correlate with clinical conditions.', '', 'CA', '', 'Pi', ''], ['CALCULATED', 'PHOTOMETRY', '', '']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimg = cv2.imread(\\'Crop/crop__1.jpg\\')\\n\\nb = py.image_to_string(img,config=\\'--oem 3\\')\\n\\n# grayscale region within bounding box\\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\\n    # resize image to three times as large as original for better readability\\ngray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\\n    # perform gaussian blur to smoothen image\\nblur = cv2.GaussianBlur(gray, (5,5), 0)\\n    #cv2.imshow(\"Gray\", gray)\\n    #cv2.waitKey(0)\\n    # threshold the image using Otsus method to preprocess for tesseract\\nret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\\ncv2.imshow(\"Otsu Threshold\", roi)\\ncv2.waitKey(0)\\n\\n        # perfrom bitwise not to flip image to black text on white background\\nroi = cv2.bitwise_not(thresh)\\n        # perform another blur on character region\\n\\n    \\n           \\ntext = py.image_to_string(roi, config=\\'--oem 3\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting elements of A\n",
    "\n",
    "B =[]\n",
    "N = len(A)\n",
    "for i in range(5):\n",
    "    a = A[i].split('\\n')\n",
    "    print(a)\n",
    "    B.append(a)\n",
    "\n",
    "print(B)\n",
    "\n",
    "\n",
    "# Conv into dictionary\n",
    "\n",
    "#declaring the dict key values\n",
    "K = [\"Test Name\", \"Unit\", \"Reference Value\", \"Value\"]\n",
    "Data = dict(zip(K,B))\n",
    "#print(Data[B])\n",
    "\n",
    "#Creating a Dataframe\n",
    "Y = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in Data.items() ]))\n",
    "\n",
    "#print(Y.columns)\n",
    "#Exporting to CSV \n",
    "Y.to_csv (r'out_csv/cust_ocr_new.csv', index = False, header=['Test Name', 'Unit', 'Reference Value', 'Value'])\n",
    "\n",
    "\n",
    "#print(Y)\n",
    "\n",
    "#------------------------for validating crop images---------------------\n",
    "'''\n",
    "img = cv2.imread('Crop/crop__1.jpg')\n",
    "\n",
    "b = py.image_to_string(img,config='--oem 3')\n",
    "\n",
    "# grayscale region within bounding box\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # resize image to three times as large as original for better readability\n",
    "gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    # perform gaussian blur to smoothen image\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    #cv2.imshow(\"Gray\", gray)\n",
    "    #cv2.waitKey(0)\n",
    "    # threshold the image using Otsus method to preprocess for tesseract\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Otsu Threshold\", roi)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "        # perfrom bitwise not to flip image to black text on white background\n",
    "roi = cv2.bitwise_not(thresh)\n",
    "        # perform another blur on character region\n",
    "\n",
    "    \n",
    "           \n",
    "text = py.image_to_string(roi, config='--oem 3')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71612613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4249903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Test Name', ['BY : SELF (7824357519), KALPANA MEDIC!', 'LAB, BIHUTOLI ROAD ,HOJAL ASSAM', '\"ASKED —s: AAROGYAM C ™', '', '']), ('Unit', ['LU ote Er to”', '', 'PHOTOMETRY', '', 'nical conditions.', '']), ('Reference Value', ['']), ('Value', ['Or ih wh TREO', '', 'A ALB/GLOBULIN RATIO', 'f GLOBULIN __', '', 'e correlate with clinical conditions.', '', 'CA', '', 'Pi', ''])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a926d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
